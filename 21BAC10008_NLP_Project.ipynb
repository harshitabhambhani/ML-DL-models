{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Project**\n",
        "(Submitted by: Harshita Bhambhani)"
      ],
      "metadata": {
        "id": "yKZo7f_DN4hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Summarization using NLP**"
      ],
      "metadata": {
        "id": "cWBBDDUtOD7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the spaCy library for natural language processing\n",
        "import spacy\n",
        "\n",
        "# Load the file\n",
        "with open(\"text for nlp.txt\", \"r\") as file:\n",
        "    # Read the contents of the file and store it in a variable\n",
        "    text = file.read()\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK3L6PwRKavQ",
        "outputId": "a09e1ad2-4298-41d7-c609-38e650264724"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"Natural Language Processing (NLP) stands at the forefront of artificial intelligence, revolutionizing the interaction between machines and human language. Rooted in the convergence of computer science, linguistics, and cognitive psychology, NLP equips computers with the ability to comprehend, interpret, and respond to natural language in a contextually aware and semantically accurate manner. Its core components, including tokenization, part-of-speech tagging, named entity recognition, parsing, and sentiment analysis, form the building blocks for various applications. From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data. Recent strides, exemplified by models like OpenAI GPT-3, showcase the prowess of deep learning and pre-training techniques, albeit accompanied by ethical considerations and challenges surrounding bias, data privacy, and environmental impact. As NLP continues to evolve, it promises a future where machines understand and generate language with unprecedented sophistication, shaping the landscape of human-computer interaction. \n",
            "In the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization. SpaCy is an open-source library that excels in providing efficient and accurate linguistic annotations for large volumes of text. Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks. The library simplicity and speed make it a popular choice for developers and researchers working on NLP applications. For text summarization specifically, spaCy can be employed in conjunction with other techniques. Extractive summarization, for instance, benefits from spaCy sentence parsing capabilities, allowing the identification of key sentences based on linguistic features. Moreover, spaCy integration with machine learning frameworks enhances its adaptability to specific summarization requirements. While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities. However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications. As the field continues to advance, spaCy is likely to play a crucial role in the development and implementation of innovative text summarization techniques.\"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input text for summarization**"
      ],
      "metadata": {
        "id": "MMCGQ258ONk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "yAYG-lnpK7Js",
        "outputId": "2b7fc37f-2212-4f61-cff1-2dab098c1996"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\"\"Natural Language Processing (NLP) stands at the forefront of artificial intelligence, revolutionizing the interaction between machines and human language. Rooted in the convergence of computer science, linguistics, and cognitive psychology, NLP equips computers with the ability to comprehend, interpret, and respond to natural language in a contextually aware and semantically accurate manner. Its core components, including tokenization, part-of-speech tagging, named entity recognition, parsing, and sentiment analysis, form the building blocks for various applications. From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data. Recent strides, exemplified by models like OpenAI GPT-3, showcase the prowess of deep learning and pre-training techniques, albeit accompanied by ethical considerations and challenges surrounding bias, data privacy, and environmental impact. As NLP continues to evolve, it promises a future where machines understand and generate language with unprecedented sophistication, shaping the landscape of human-computer interaction. \\nIn the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization. SpaCy is an open-source library that excels in providing efficient and accurate linguistic annotations for large volumes of text. Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks. The library simplicity and speed make it a popular choice for developers and researchers working on NLP applications. For text summarization specifically, spaCy can be employed in conjunction with other techniques. Extractive summarization, for instance, benefits from spaCy sentence parsing capabilities, allowing the identification of key sentences based on linguistic features. Moreover, spaCy integration with machine learning frameworks enhances its adaptability to specific summarization requirements. While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities. However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications. As the field continues to advance, spaCy is likely to play a crucial role in the development and implementation of innovative text summarization techniques.\"\"\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stop words from spaCy and common punctuation symbols\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "\n",
        "# Create a list of stop words\n",
        "stopwords = list(STOP_WORDS)\n",
        "stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTQLEl4zK_e-",
        "outputId": "480269dd-0865-4138-98ba-08c843f8e31b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['below',\n",
              " 'whereupon',\n",
              " 'any',\n",
              " 'does',\n",
              " 'i',\n",
              " 'side',\n",
              " 'seeming',\n",
              " 'regarding',\n",
              " 'becoming',\n",
              " 'anywhere',\n",
              " 'without',\n",
              " 'off',\n",
              " 'might',\n",
              " \"'s\",\n",
              " 're',\n",
              " 'indeed',\n",
              " 'since',\n",
              " 'thru',\n",
              " 'were',\n",
              " 'wherever',\n",
              " 'ourselves',\n",
              " '‘ve',\n",
              " 'that',\n",
              " 'but',\n",
              " 'always',\n",
              " 'beforehand',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'a',\n",
              " 'show',\n",
              " 'top',\n",
              " 'sometime',\n",
              " 'becomes',\n",
              " 'whether',\n",
              " 'well',\n",
              " 'itself',\n",
              " 'then',\n",
              " 'yourself',\n",
              " 'really',\n",
              " \"'re\",\n",
              " 'against',\n",
              " 'fifteen',\n",
              " 'the',\n",
              " 'are',\n",
              " '’m',\n",
              " 'therefore',\n",
              " 'n’t',\n",
              " 'used',\n",
              " 'can',\n",
              " 'seems',\n",
              " 'please',\n",
              " 'through',\n",
              " 'and',\n",
              " 'an',\n",
              " 'sometimes',\n",
              " 'he',\n",
              " 'as',\n",
              " 'herself',\n",
              " 'else',\n",
              " 'do',\n",
              " 'part',\n",
              " 'enough',\n",
              " '’ve',\n",
              " 'yourselves',\n",
              " '‘re',\n",
              " 'some',\n",
              " 'will',\n",
              " 'six',\n",
              " 'nothing',\n",
              " 'eight',\n",
              " 'three',\n",
              " 'how',\n",
              " 'last',\n",
              " 'various',\n",
              " 'whenever',\n",
              " 'either',\n",
              " 'together',\n",
              " 'call',\n",
              " 'which',\n",
              " 'nowhere',\n",
              " 'your',\n",
              " 'meanwhile',\n",
              " 'never',\n",
              " 'though',\n",
              " 'is',\n",
              " 'doing',\n",
              " \"'ll\",\n",
              " 'front',\n",
              " 'anyhow',\n",
              " 'onto',\n",
              " 'up',\n",
              " 'everything',\n",
              " '‘m',\n",
              " 'thereupon',\n",
              " 'to',\n",
              " 'otherwise',\n",
              " 'whole',\n",
              " 'no',\n",
              " 'least',\n",
              " 'we',\n",
              " 'four',\n",
              " 'toward',\n",
              " \"'d\",\n",
              " 'therein',\n",
              " 'had',\n",
              " 'after',\n",
              " 'about',\n",
              " 'noone',\n",
              " 'while',\n",
              " 'many',\n",
              " 'it',\n",
              " 'made',\n",
              " 'for',\n",
              " 'former',\n",
              " 'above',\n",
              " 'there',\n",
              " 'latter',\n",
              " 'whither',\n",
              " 'further',\n",
              " 'seemed',\n",
              " 'thus',\n",
              " 'only',\n",
              " 'twenty',\n",
              " 'afterwards',\n",
              " 'moreover',\n",
              " 'less',\n",
              " 'quite',\n",
              " 'several',\n",
              " 'via',\n",
              " 'must',\n",
              " 'before',\n",
              " 'eleven',\n",
              " 'whereby',\n",
              " 'hundred',\n",
              " 'something',\n",
              " 'anyone',\n",
              " 'same',\n",
              " 'take',\n",
              " 'where',\n",
              " 'whoever',\n",
              " 'what',\n",
              " 'hers',\n",
              " 'amongst',\n",
              " 'say',\n",
              " 'twelve',\n",
              " 'due',\n",
              " 'who',\n",
              " 'with',\n",
              " 'seem',\n",
              " 'they',\n",
              " 'every',\n",
              " 'hereafter',\n",
              " 'not',\n",
              " 'own',\n",
              " 'at',\n",
              " 'his',\n",
              " 'when',\n",
              " 'down',\n",
              " 'if',\n",
              " 'still',\n",
              " 'here',\n",
              " 'someone',\n",
              " 'anyway',\n",
              " 'thereafter',\n",
              " 'few',\n",
              " 'whatever',\n",
              " 'may',\n",
              " 'anything',\n",
              " 'those',\n",
              " 'rather',\n",
              " 'throughout',\n",
              " 'our',\n",
              " 'see',\n",
              " 'thence',\n",
              " 'often',\n",
              " 'into',\n",
              " 'why',\n",
              " 'make',\n",
              " 'other',\n",
              " 'somewhere',\n",
              " 'ever',\n",
              " 'behind',\n",
              " 'very',\n",
              " 'formerly',\n",
              " 'amount',\n",
              " 'so',\n",
              " 'was',\n",
              " 'almost',\n",
              " 'whereas',\n",
              " 'beside',\n",
              " '‘ll',\n",
              " 'around',\n",
              " 'her',\n",
              " 'unless',\n",
              " 'ca',\n",
              " 'done',\n",
              " 'thereby',\n",
              " 'be',\n",
              " 'next',\n",
              " 'first',\n",
              " 'two',\n",
              " 'go',\n",
              " 'on',\n",
              " 'whose',\n",
              " 'somehow',\n",
              " 'by',\n",
              " 'whence',\n",
              " 'across',\n",
              " 'full',\n",
              " 'this',\n",
              " \"'ve\",\n",
              " 'she',\n",
              " 'get',\n",
              " 'third',\n",
              " 'until',\n",
              " 'forty',\n",
              " 'within',\n",
              " 'another',\n",
              " 'much',\n",
              " 'yours',\n",
              " 'besides',\n",
              " 'become',\n",
              " 'using',\n",
              " '’d',\n",
              " 'should',\n",
              " 'out',\n",
              " 'each',\n",
              " 'move',\n",
              " 'nobody',\n",
              " 'being',\n",
              " 'could',\n",
              " 'would',\n",
              " 'per',\n",
              " '’re',\n",
              " 'latterly',\n",
              " 'put',\n",
              " 'one',\n",
              " 'in',\n",
              " 'too',\n",
              " 'them',\n",
              " 'or',\n",
              " 'nor',\n",
              " 'myself',\n",
              " 'yet',\n",
              " 'have',\n",
              " 'give',\n",
              " 'everyone',\n",
              " \"'m\",\n",
              " 'their',\n",
              " 'during',\n",
              " 'ten',\n",
              " 'just',\n",
              " 'name',\n",
              " 'him',\n",
              " 'more',\n",
              " 'from',\n",
              " 'along',\n",
              " 'such',\n",
              " 'perhaps',\n",
              " 'of',\n",
              " 'all',\n",
              " 'over',\n",
              " 'mostly',\n",
              " 'you',\n",
              " 'except',\n",
              " 'alone',\n",
              " '’s',\n",
              " 'himself',\n",
              " 'cannot',\n",
              " 'bottom',\n",
              " 'most',\n",
              " 'among',\n",
              " 'none',\n",
              " 'us',\n",
              " 'nine',\n",
              " 'has',\n",
              " 'others',\n",
              " 'hence',\n",
              " 'because',\n",
              " 'am',\n",
              " 'again',\n",
              " 'sixty',\n",
              " 'upon',\n",
              " 'than',\n",
              " 'its',\n",
              " 'keep',\n",
              " 'already',\n",
              " 'neither',\n",
              " '’ll',\n",
              " 'mine',\n",
              " 'also',\n",
              " 'elsewhere',\n",
              " 'these',\n",
              " 'became',\n",
              " 'serious',\n",
              " 'empty',\n",
              " 'under',\n",
              " 'five',\n",
              " \"n't\",\n",
              " 'did',\n",
              " 'ours',\n",
              " 'although',\n",
              " 'whom',\n",
              " 'me',\n",
              " 'wherein',\n",
              " 'my',\n",
              " '‘s',\n",
              " 'now',\n",
              " 'been',\n",
              " 'n‘t',\n",
              " 'hereupon',\n",
              " 'fifty',\n",
              " 'once',\n",
              " 'namely',\n",
              " 'towards',\n",
              " 'nevertheless',\n",
              " 'even',\n",
              " 'everywhere',\n",
              " 'whereafter',\n",
              " 'back',\n",
              " 'herein',\n",
              " 'hereby',\n",
              " '‘d',\n",
              " 'however',\n",
              " 'themselves',\n",
              " 'both']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of stopwords\n",
        "len(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJNM_iYWLIGE",
        "outputId": "d2c6a738-e7d1-4f47-a2c9-e40d41fc90fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy's English language model\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "metadata": {
        "id": "uc-95IkULPYN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the punctuation symbols\n",
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MzTtOCXTLRME",
        "outputId": "f43be0e6-3520-470c-e54a-92b2150e1ef8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input text using spaCy\n",
        "doc = nlp(text)\n"
      ],
      "metadata": {
        "id": "0Og1PJd_LYb0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract individual tokens from the document\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ5bBxkhLbrk",
        "outputId": "c3838496-995b-4c20-8642-fa5d5e8f04de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"', '\"', '\"', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'stands', 'at', 'the', 'forefront', 'of', 'artificial', 'intelligence', ',', 'revolutionizing', 'the', 'interaction', 'between', 'machines', 'and', 'human', 'language', '.', 'Rooted', 'in', 'the', 'convergence', 'of', 'computer', 'science', ',', 'linguistics', ',', 'and', 'cognitive', 'psychology', ',', 'NLP', 'equips', 'computers', 'with', 'the', 'ability', 'to', 'comprehend', ',', 'interpret', ',', 'and', 'respond', 'to', 'natural', 'language', 'in', 'a', 'contextually', 'aware', 'and', 'semantically', 'accurate', 'manner', '.', 'Its', 'core', 'components', ',', 'including', 'tokenization', ',', 'part', '-', 'of', '-', 'speech', 'tagging', ',', 'named', 'entity', 'recognition', ',', 'parsing', ',', 'and', 'sentiment', 'analysis', ',', 'form', 'the', 'building', 'blocks', 'for', 'various', 'applications', '.', 'From', 'the', 'conversational', 'capabilities', 'of', 'chatbots', 'and', 'virtual', 'assistants', 'to', 'language', 'translation', ',', 'information', 'extraction', ',', 'text', 'summarization', ',', 'and', 'speech', 'recognition', ',', 'NLP', 'permeates', 'diverse', 'sectors', ',', 'enhancing', 'user', 'experiences', 'and', 'extracting', 'valuable', 'insights', 'from', 'unstructured', 'data', '.', 'Recent', 'strides', ',', 'exemplified', 'by', 'models', 'like', 'OpenAI', 'GPT-3', ',', 'showcase', 'the', 'prowess', 'of', 'deep', 'learning', 'and', 'pre', '-', 'training', 'techniques', ',', 'albeit', 'accompanied', 'by', 'ethical', 'considerations', 'and', 'challenges', 'surrounding', 'bias', ',', 'data', 'privacy', ',', 'and', 'environmental', 'impact', '.', 'As', 'NLP', 'continues', 'to', 'evolve', ',', 'it', 'promises', 'a', 'future', 'where', 'machines', 'understand', 'and', 'generate', 'language', 'with', 'unprecedented', 'sophistication', ',', 'shaping', 'the', 'landscape', 'of', 'human', '-', 'computer', 'interaction', '.', '\\n', 'In', 'the', 'realm', 'of', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'the', 'spaCy', 'library', 'stands', 'as', 'a', 'powerful', 'tool', ',', 'offering', 'robust', 'support', 'for', 'various', 'text', 'processing', 'tasks', ',', 'including', 'text', 'summarization', '.', 'SpaCy', 'is', 'an', 'open', '-', 'source', 'library', 'that', 'excels', 'in', 'providing', 'efficient', 'and', 'accurate', 'linguistic', 'annotations', 'for', 'large', 'volumes', 'of', 'text', '.', 'Leveraging', 'pre', '-', 'trained', 'models', ',', 'spaCy', 'facilitates', 'tokenization', ',', 'part', '-', 'of', '-', 'speech', 'tagging', ',', 'named', 'entity', 'recognition', ',', 'and', 'syntactic', 'parsing', ',', 'forming', 'a', 'solid', 'foundation', 'for', 'summarization', 'tasks', '.', 'The', 'library', 'simplicity', 'and', 'speed', 'make', 'it', 'a', 'popular', 'choice', 'for', 'developers', 'and', 'researchers', 'working', 'on', 'NLP', 'applications', '.', 'For', 'text', 'summarization', 'specifically', ',', 'spaCy', 'can', 'be', 'employed', 'in', 'conjunction', 'with', 'other', 'techniques', '.', 'Extractive', 'summarization', ',', 'for', 'instance', ',', 'benefits', 'from', 'spaCy', 'sentence', 'parsing', 'capabilities', ',', 'allowing', 'the', 'identification', 'of', 'key', 'sentences', 'based', 'on', 'linguistic', 'features', '.', 'Moreover', ',', 'spaCy', 'integration', 'with', 'machine', 'learning', 'frameworks', 'enhances', 'its', 'adaptability', 'to', 'specific', 'summarization', 'requirements', '.', 'While', 'spaCy', 'is', 'renowned', 'for', 'its', 'efficiency', 'and', 'ease', 'of', 'use', ',', 'it', 'essential', 'to', 'note', 'that', 'abstractive', 'summarization', ',', 'which', 'involves', 'generating', 'new', 'sentences', ',', 'often', 'requires', 'more', 'sophisticated', 'models', 'beyond', 'spaCy', 'primary', 'capabilities', '.', 'However', ',', 'the', 'library', 'remains', 'a', 'valuable', 'asset', 'in', 'the', 'preprocessing', 'stages', 'of', 'text', 'summarization', 'pipelines', ',', 'contributing', 'to', 'the', 'overall', 'effectiveness', 'of', 'NLP', 'applications', '.', 'As', 'the', 'field', 'continues', 'to', 'advance', ',', 'spaCy', 'is', 'likely', 'to', 'play', 'a', 'crucial', 'role', 'in', 'the', 'development', 'and', 'implementation', 'of', 'innovative', 'text', 'summarization', 'techniques', '.', '\"', '\"', '\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpPUsd-rLczt",
        "outputId": "7f404c40-07c3-42a9-cb17-d600267e07bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"',\n",
              " '\"',\n",
              " '\"',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'stands',\n",
              " 'at',\n",
              " 'the',\n",
              " 'forefront',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " ',',\n",
              " 'revolutionizing',\n",
              " 'the',\n",
              " 'interaction',\n",
              " 'between',\n",
              " 'machines',\n",
              " 'and',\n",
              " 'human',\n",
              " 'language',\n",
              " '.',\n",
              " 'Rooted',\n",
              " 'in',\n",
              " 'the',\n",
              " 'convergence',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science',\n",
              " ',',\n",
              " 'linguistics',\n",
              " ',',\n",
              " 'and',\n",
              " 'cognitive',\n",
              " 'psychology',\n",
              " ',',\n",
              " 'NLP',\n",
              " 'equips',\n",
              " 'computers',\n",
              " 'with',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'comprehend',\n",
              " ',',\n",
              " 'interpret',\n",
              " ',',\n",
              " 'and',\n",
              " 'respond',\n",
              " 'to',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'in',\n",
              " 'a',\n",
              " 'contextually',\n",
              " 'aware',\n",
              " 'and',\n",
              " 'semantically',\n",
              " 'accurate',\n",
              " 'manner',\n",
              " '.',\n",
              " 'Its',\n",
              " 'core',\n",
              " 'components',\n",
              " ',',\n",
              " 'including',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'part',\n",
              " '-',\n",
              " 'of',\n",
              " '-',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " ',',\n",
              " 'named',\n",
              " 'entity',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'parsing',\n",
              " ',',\n",
              " 'and',\n",
              " 'sentiment',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'form',\n",
              " 'the',\n",
              " 'building',\n",
              " 'blocks',\n",
              " 'for',\n",
              " 'various',\n",
              " 'applications',\n",
              " '.',\n",
              " 'From',\n",
              " 'the',\n",
              " 'conversational',\n",
              " 'capabilities',\n",
              " 'of',\n",
              " 'chatbots',\n",
              " 'and',\n",
              " 'virtual',\n",
              " 'assistants',\n",
              " 'to',\n",
              " 'language',\n",
              " 'translation',\n",
              " ',',\n",
              " 'information',\n",
              " 'extraction',\n",
              " ',',\n",
              " 'text',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'and',\n",
              " 'speech',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'NLP',\n",
              " 'permeates',\n",
              " 'diverse',\n",
              " 'sectors',\n",
              " ',',\n",
              " 'enhancing',\n",
              " 'user',\n",
              " 'experiences',\n",
              " 'and',\n",
              " 'extracting',\n",
              " 'valuable',\n",
              " 'insights',\n",
              " 'from',\n",
              " 'unstructured',\n",
              " 'data',\n",
              " '.',\n",
              " 'Recent',\n",
              " 'strides',\n",
              " ',',\n",
              " 'exemplified',\n",
              " 'by',\n",
              " 'models',\n",
              " 'like',\n",
              " 'OpenAI',\n",
              " 'GPT-3',\n",
              " ',',\n",
              " 'showcase',\n",
              " 'the',\n",
              " 'prowess',\n",
              " 'of',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'pre',\n",
              " '-',\n",
              " 'training',\n",
              " 'techniques',\n",
              " ',',\n",
              " 'albeit',\n",
              " 'accompanied',\n",
              " 'by',\n",
              " 'ethical',\n",
              " 'considerations',\n",
              " 'and',\n",
              " 'challenges',\n",
              " 'surrounding',\n",
              " 'bias',\n",
              " ',',\n",
              " 'data',\n",
              " 'privacy',\n",
              " ',',\n",
              " 'and',\n",
              " 'environmental',\n",
              " 'impact',\n",
              " '.',\n",
              " 'As',\n",
              " 'NLP',\n",
              " 'continues',\n",
              " 'to',\n",
              " 'evolve',\n",
              " ',',\n",
              " 'it',\n",
              " 'promises',\n",
              " 'a',\n",
              " 'future',\n",
              " 'where',\n",
              " 'machines',\n",
              " 'understand',\n",
              " 'and',\n",
              " 'generate',\n",
              " 'language',\n",
              " 'with',\n",
              " 'unprecedented',\n",
              " 'sophistication',\n",
              " ',',\n",
              " 'shaping',\n",
              " 'the',\n",
              " 'landscape',\n",
              " 'of',\n",
              " 'human',\n",
              " '-',\n",
              " 'computer',\n",
              " 'interaction',\n",
              " '.',\n",
              " '\\n',\n",
              " 'In',\n",
              " 'the',\n",
              " 'realm',\n",
              " 'of',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " ',',\n",
              " 'the',\n",
              " 'spaCy',\n",
              " 'library',\n",
              " 'stands',\n",
              " 'as',\n",
              " 'a',\n",
              " 'powerful',\n",
              " 'tool',\n",
              " ',',\n",
              " 'offering',\n",
              " 'robust',\n",
              " 'support',\n",
              " 'for',\n",
              " 'various',\n",
              " 'text',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " ',',\n",
              " 'including',\n",
              " 'text',\n",
              " 'summarization',\n",
              " '.',\n",
              " 'SpaCy',\n",
              " 'is',\n",
              " 'an',\n",
              " 'open',\n",
              " '-',\n",
              " 'source',\n",
              " 'library',\n",
              " 'that',\n",
              " 'excels',\n",
              " 'in',\n",
              " 'providing',\n",
              " 'efficient',\n",
              " 'and',\n",
              " 'accurate',\n",
              " 'linguistic',\n",
              " 'annotations',\n",
              " 'for',\n",
              " 'large',\n",
              " 'volumes',\n",
              " 'of',\n",
              " 'text',\n",
              " '.',\n",
              " 'Leveraging',\n",
              " 'pre',\n",
              " '-',\n",
              " 'trained',\n",
              " 'models',\n",
              " ',',\n",
              " 'spaCy',\n",
              " 'facilitates',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'part',\n",
              " '-',\n",
              " 'of',\n",
              " '-',\n",
              " 'speech',\n",
              " 'tagging',\n",
              " ',',\n",
              " 'named',\n",
              " 'entity',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'and',\n",
              " 'syntactic',\n",
              " 'parsing',\n",
              " ',',\n",
              " 'forming',\n",
              " 'a',\n",
              " 'solid',\n",
              " 'foundation',\n",
              " 'for',\n",
              " 'summarization',\n",
              " 'tasks',\n",
              " '.',\n",
              " 'The',\n",
              " 'library',\n",
              " 'simplicity',\n",
              " 'and',\n",
              " 'speed',\n",
              " 'make',\n",
              " 'it',\n",
              " 'a',\n",
              " 'popular',\n",
              " 'choice',\n",
              " 'for',\n",
              " 'developers',\n",
              " 'and',\n",
              " 'researchers',\n",
              " 'working',\n",
              " 'on',\n",
              " 'NLP',\n",
              " 'applications',\n",
              " '.',\n",
              " 'For',\n",
              " 'text',\n",
              " 'summarization',\n",
              " 'specifically',\n",
              " ',',\n",
              " 'spaCy',\n",
              " 'can',\n",
              " 'be',\n",
              " 'employed',\n",
              " 'in',\n",
              " 'conjunction',\n",
              " 'with',\n",
              " 'other',\n",
              " 'techniques',\n",
              " '.',\n",
              " 'Extractive',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'for',\n",
              " 'instance',\n",
              " ',',\n",
              " 'benefits',\n",
              " 'from',\n",
              " 'spaCy',\n",
              " 'sentence',\n",
              " 'parsing',\n",
              " 'capabilities',\n",
              " ',',\n",
              " 'allowing',\n",
              " 'the',\n",
              " 'identification',\n",
              " 'of',\n",
              " 'key',\n",
              " 'sentences',\n",
              " 'based',\n",
              " 'on',\n",
              " 'linguistic',\n",
              " 'features',\n",
              " '.',\n",
              " 'Moreover',\n",
              " ',',\n",
              " 'spaCy',\n",
              " 'integration',\n",
              " 'with',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'frameworks',\n",
              " 'enhances',\n",
              " 'its',\n",
              " 'adaptability',\n",
              " 'to',\n",
              " 'specific',\n",
              " 'summarization',\n",
              " 'requirements',\n",
              " '.',\n",
              " 'While',\n",
              " 'spaCy',\n",
              " 'is',\n",
              " 'renowned',\n",
              " 'for',\n",
              " 'its',\n",
              " 'efficiency',\n",
              " 'and',\n",
              " 'ease',\n",
              " 'of',\n",
              " 'use',\n",
              " ',',\n",
              " 'it',\n",
              " 'essential',\n",
              " 'to',\n",
              " 'note',\n",
              " 'that',\n",
              " 'abstractive',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'which',\n",
              " 'involves',\n",
              " 'generating',\n",
              " 'new',\n",
              " 'sentences',\n",
              " ',',\n",
              " 'often',\n",
              " 'requires',\n",
              " 'more',\n",
              " 'sophisticated',\n",
              " 'models',\n",
              " 'beyond',\n",
              " 'spaCy',\n",
              " 'primary',\n",
              " 'capabilities',\n",
              " '.',\n",
              " 'However',\n",
              " ',',\n",
              " 'the',\n",
              " 'library',\n",
              " 'remains',\n",
              " 'a',\n",
              " 'valuable',\n",
              " 'asset',\n",
              " 'in',\n",
              " 'the',\n",
              " 'preprocessing',\n",
              " 'stages',\n",
              " 'of',\n",
              " 'text',\n",
              " 'summarization',\n",
              " 'pipelines',\n",
              " ',',\n",
              " 'contributing',\n",
              " 'to',\n",
              " 'the',\n",
              " 'overall',\n",
              " 'effectiveness',\n",
              " 'of',\n",
              " 'NLP',\n",
              " 'applications',\n",
              " '.',\n",
              " 'As',\n",
              " 'the',\n",
              " 'field',\n",
              " 'continues',\n",
              " 'to',\n",
              " 'advance',\n",
              " ',',\n",
              " 'spaCy',\n",
              " 'is',\n",
              " 'likely',\n",
              " 'to',\n",
              " 'play',\n",
              " 'a',\n",
              " 'crucial',\n",
              " 'role',\n",
              " 'in',\n",
              " 'the',\n",
              " 'development',\n",
              " 'and',\n",
              " 'implementation',\n",
              " 'of',\n",
              " 'innovative',\n",
              " 'text',\n",
              " 'summarization',\n",
              " 'techniques',\n",
              " '.',\n",
              " '\"',\n",
              " '\"',\n",
              " '\"']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of tokens in the document\n",
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T1iBTNSLgno",
        "outputId": "1bff495a-74a0-4f62-ab6b-31ebaf42ca16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate word frequencies in the document, excluding stop words and punctuation\n",
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "    if word.text.lower() not in stopwords:\n",
        "        if word.text.lower() not in punctuation:\n",
        "            if word.text not in word_frequencies.keys():\n",
        "                word_frequencies[word.text] = 1\n",
        "            else:\n",
        "                word_frequencies[word.text] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "dIfJqfJNLj6l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display word frequencies\n",
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS5U90IWLr3G",
        "outputId": "b6fd5c88-fd87-4e26-9cc3-1f4f99069b3f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Natural': 2,\n",
              " 'Language': 2,\n",
              " 'Processing': 2,\n",
              " 'NLP': 7,\n",
              " 'stands': 2,\n",
              " 'forefront': 1,\n",
              " 'artificial': 1,\n",
              " 'intelligence': 1,\n",
              " 'revolutionizing': 1,\n",
              " 'interaction': 2,\n",
              " 'machines': 2,\n",
              " 'human': 2,\n",
              " 'language': 4,\n",
              " 'Rooted': 1,\n",
              " 'convergence': 1,\n",
              " 'computer': 2,\n",
              " 'science': 1,\n",
              " 'linguistics': 1,\n",
              " 'cognitive': 1,\n",
              " 'psychology': 1,\n",
              " 'equips': 1,\n",
              " 'computers': 1,\n",
              " 'ability': 1,\n",
              " 'comprehend': 1,\n",
              " 'interpret': 1,\n",
              " 'respond': 1,\n",
              " 'natural': 1,\n",
              " 'contextually': 1,\n",
              " 'aware': 1,\n",
              " 'semantically': 1,\n",
              " 'accurate': 2,\n",
              " 'manner': 1,\n",
              " 'core': 1,\n",
              " 'components': 1,\n",
              " 'including': 2,\n",
              " 'tokenization': 2,\n",
              " 'speech': 3,\n",
              " 'tagging': 2,\n",
              " 'named': 2,\n",
              " 'entity': 2,\n",
              " 'recognition': 3,\n",
              " 'parsing': 3,\n",
              " 'sentiment': 1,\n",
              " 'analysis': 1,\n",
              " 'form': 1,\n",
              " 'building': 1,\n",
              " 'blocks': 1,\n",
              " 'applications': 3,\n",
              " 'conversational': 1,\n",
              " 'capabilities': 3,\n",
              " 'chatbots': 1,\n",
              " 'virtual': 1,\n",
              " 'assistants': 1,\n",
              " 'translation': 1,\n",
              " 'information': 1,\n",
              " 'extraction': 1,\n",
              " 'text': 7,\n",
              " 'summarization': 9,\n",
              " 'permeates': 1,\n",
              " 'diverse': 1,\n",
              " 'sectors': 1,\n",
              " 'enhancing': 1,\n",
              " 'user': 1,\n",
              " 'experiences': 1,\n",
              " 'extracting': 1,\n",
              " 'valuable': 2,\n",
              " 'insights': 1,\n",
              " 'unstructured': 1,\n",
              " 'data': 2,\n",
              " 'Recent': 1,\n",
              " 'strides': 1,\n",
              " 'exemplified': 1,\n",
              " 'models': 3,\n",
              " 'like': 1,\n",
              " 'OpenAI': 1,\n",
              " 'GPT-3': 1,\n",
              " 'showcase': 1,\n",
              " 'prowess': 1,\n",
              " 'deep': 1,\n",
              " 'learning': 2,\n",
              " 'pre': 2,\n",
              " 'training': 1,\n",
              " 'techniques': 3,\n",
              " 'albeit': 1,\n",
              " 'accompanied': 1,\n",
              " 'ethical': 1,\n",
              " 'considerations': 1,\n",
              " 'challenges': 1,\n",
              " 'surrounding': 1,\n",
              " 'bias': 1,\n",
              " 'privacy': 1,\n",
              " 'environmental': 1,\n",
              " 'impact': 1,\n",
              " 'continues': 2,\n",
              " 'evolve': 1,\n",
              " 'promises': 1,\n",
              " 'future': 1,\n",
              " 'understand': 1,\n",
              " 'generate': 1,\n",
              " 'unprecedented': 1,\n",
              " 'sophistication': 1,\n",
              " 'shaping': 1,\n",
              " 'landscape': 1,\n",
              " '\\n': 1,\n",
              " 'realm': 1,\n",
              " 'spaCy': 8,\n",
              " 'library': 4,\n",
              " 'powerful': 1,\n",
              " 'tool': 1,\n",
              " 'offering': 1,\n",
              " 'robust': 1,\n",
              " 'support': 1,\n",
              " 'processing': 1,\n",
              " 'tasks': 2,\n",
              " 'SpaCy': 1,\n",
              " 'open': 1,\n",
              " 'source': 1,\n",
              " 'excels': 1,\n",
              " 'providing': 1,\n",
              " 'efficient': 1,\n",
              " 'linguistic': 2,\n",
              " 'annotations': 1,\n",
              " 'large': 1,\n",
              " 'volumes': 1,\n",
              " 'Leveraging': 1,\n",
              " 'trained': 1,\n",
              " 'facilitates': 1,\n",
              " 'syntactic': 1,\n",
              " 'forming': 1,\n",
              " 'solid': 1,\n",
              " 'foundation': 1,\n",
              " 'simplicity': 1,\n",
              " 'speed': 1,\n",
              " 'popular': 1,\n",
              " 'choice': 1,\n",
              " 'developers': 1,\n",
              " 'researchers': 1,\n",
              " 'working': 1,\n",
              " 'specifically': 1,\n",
              " 'employed': 1,\n",
              " 'conjunction': 1,\n",
              " 'Extractive': 1,\n",
              " 'instance': 1,\n",
              " 'benefits': 1,\n",
              " 'sentence': 1,\n",
              " 'allowing': 1,\n",
              " 'identification': 1,\n",
              " 'key': 1,\n",
              " 'sentences': 2,\n",
              " 'based': 1,\n",
              " 'features': 1,\n",
              " 'integration': 1,\n",
              " 'machine': 1,\n",
              " 'frameworks': 1,\n",
              " 'enhances': 1,\n",
              " 'adaptability': 1,\n",
              " 'specific': 1,\n",
              " 'requirements': 1,\n",
              " 'renowned': 1,\n",
              " 'efficiency': 1,\n",
              " 'ease': 1,\n",
              " 'use': 1,\n",
              " 'essential': 1,\n",
              " 'note': 1,\n",
              " 'abstractive': 1,\n",
              " 'involves': 1,\n",
              " 'generating': 1,\n",
              " 'new': 1,\n",
              " 'requires': 1,\n",
              " 'sophisticated': 1,\n",
              " 'primary': 1,\n",
              " 'remains': 1,\n",
              " 'asset': 1,\n",
              " 'preprocessing': 1,\n",
              " 'stages': 1,\n",
              " 'pipelines': 1,\n",
              " 'contributing': 1,\n",
              " 'overall': 1,\n",
              " 'effectiveness': 1,\n",
              " 'field': 1,\n",
              " 'advance': 1,\n",
              " 'likely': 1,\n",
              " 'play': 1,\n",
              " 'crucial': 1,\n",
              " 'role': 1,\n",
              " 'development': 1,\n",
              " 'implementation': 1,\n",
              " 'innovative': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of unique words in the document\n",
        "len(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dV9I4JWLs9D",
        "outputId": "f8e49b56-4b4c-4581-854c-73c9d1c48a23"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize word frequencies by dividing each frequency by the maximum frequency\n",
        "max_frequency = max(word_frequencies.values())\n",
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VQNcrcYLxIn",
        "outputId": "2fedb180-a4d3-4124-b1a3-ed8c54355bc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update word frequencies to represent the normalized values\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word]/max_frequency\n",
        "\n",
        "# Display the normalized word frequencies\n",
        "word_frequencies\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V96W5ODbL2TX",
        "outputId": "43a4acb1-0d57-411d-f360-8ffcdb0cca83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Natural': 0.2222222222222222,\n",
              " 'Language': 0.2222222222222222,\n",
              " 'Processing': 0.2222222222222222,\n",
              " 'NLP': 0.7777777777777778,\n",
              " 'stands': 0.2222222222222222,\n",
              " 'forefront': 0.1111111111111111,\n",
              " 'artificial': 0.1111111111111111,\n",
              " 'intelligence': 0.1111111111111111,\n",
              " 'revolutionizing': 0.1111111111111111,\n",
              " 'interaction': 0.2222222222222222,\n",
              " 'machines': 0.2222222222222222,\n",
              " 'human': 0.2222222222222222,\n",
              " 'language': 0.4444444444444444,\n",
              " 'Rooted': 0.1111111111111111,\n",
              " 'convergence': 0.1111111111111111,\n",
              " 'computer': 0.2222222222222222,\n",
              " 'science': 0.1111111111111111,\n",
              " 'linguistics': 0.1111111111111111,\n",
              " 'cognitive': 0.1111111111111111,\n",
              " 'psychology': 0.1111111111111111,\n",
              " 'equips': 0.1111111111111111,\n",
              " 'computers': 0.1111111111111111,\n",
              " 'ability': 0.1111111111111111,\n",
              " 'comprehend': 0.1111111111111111,\n",
              " 'interpret': 0.1111111111111111,\n",
              " 'respond': 0.1111111111111111,\n",
              " 'natural': 0.1111111111111111,\n",
              " 'contextually': 0.1111111111111111,\n",
              " 'aware': 0.1111111111111111,\n",
              " 'semantically': 0.1111111111111111,\n",
              " 'accurate': 0.2222222222222222,\n",
              " 'manner': 0.1111111111111111,\n",
              " 'core': 0.1111111111111111,\n",
              " 'components': 0.1111111111111111,\n",
              " 'including': 0.2222222222222222,\n",
              " 'tokenization': 0.2222222222222222,\n",
              " 'speech': 0.3333333333333333,\n",
              " 'tagging': 0.2222222222222222,\n",
              " 'named': 0.2222222222222222,\n",
              " 'entity': 0.2222222222222222,\n",
              " 'recognition': 0.3333333333333333,\n",
              " 'parsing': 0.3333333333333333,\n",
              " 'sentiment': 0.1111111111111111,\n",
              " 'analysis': 0.1111111111111111,\n",
              " 'form': 0.1111111111111111,\n",
              " 'building': 0.1111111111111111,\n",
              " 'blocks': 0.1111111111111111,\n",
              " 'applications': 0.3333333333333333,\n",
              " 'conversational': 0.1111111111111111,\n",
              " 'capabilities': 0.3333333333333333,\n",
              " 'chatbots': 0.1111111111111111,\n",
              " 'virtual': 0.1111111111111111,\n",
              " 'assistants': 0.1111111111111111,\n",
              " 'translation': 0.1111111111111111,\n",
              " 'information': 0.1111111111111111,\n",
              " 'extraction': 0.1111111111111111,\n",
              " 'text': 0.7777777777777778,\n",
              " 'summarization': 1.0,\n",
              " 'permeates': 0.1111111111111111,\n",
              " 'diverse': 0.1111111111111111,\n",
              " 'sectors': 0.1111111111111111,\n",
              " 'enhancing': 0.1111111111111111,\n",
              " 'user': 0.1111111111111111,\n",
              " 'experiences': 0.1111111111111111,\n",
              " 'extracting': 0.1111111111111111,\n",
              " 'valuable': 0.2222222222222222,\n",
              " 'insights': 0.1111111111111111,\n",
              " 'unstructured': 0.1111111111111111,\n",
              " 'data': 0.2222222222222222,\n",
              " 'Recent': 0.1111111111111111,\n",
              " 'strides': 0.1111111111111111,\n",
              " 'exemplified': 0.1111111111111111,\n",
              " 'models': 0.3333333333333333,\n",
              " 'like': 0.1111111111111111,\n",
              " 'OpenAI': 0.1111111111111111,\n",
              " 'GPT-3': 0.1111111111111111,\n",
              " 'showcase': 0.1111111111111111,\n",
              " 'prowess': 0.1111111111111111,\n",
              " 'deep': 0.1111111111111111,\n",
              " 'learning': 0.2222222222222222,\n",
              " 'pre': 0.2222222222222222,\n",
              " 'training': 0.1111111111111111,\n",
              " 'techniques': 0.3333333333333333,\n",
              " 'albeit': 0.1111111111111111,\n",
              " 'accompanied': 0.1111111111111111,\n",
              " 'ethical': 0.1111111111111111,\n",
              " 'considerations': 0.1111111111111111,\n",
              " 'challenges': 0.1111111111111111,\n",
              " 'surrounding': 0.1111111111111111,\n",
              " 'bias': 0.1111111111111111,\n",
              " 'privacy': 0.1111111111111111,\n",
              " 'environmental': 0.1111111111111111,\n",
              " 'impact': 0.1111111111111111,\n",
              " 'continues': 0.2222222222222222,\n",
              " 'evolve': 0.1111111111111111,\n",
              " 'promises': 0.1111111111111111,\n",
              " 'future': 0.1111111111111111,\n",
              " 'understand': 0.1111111111111111,\n",
              " 'generate': 0.1111111111111111,\n",
              " 'unprecedented': 0.1111111111111111,\n",
              " 'sophistication': 0.1111111111111111,\n",
              " 'shaping': 0.1111111111111111,\n",
              " 'landscape': 0.1111111111111111,\n",
              " '\\n': 0.1111111111111111,\n",
              " 'realm': 0.1111111111111111,\n",
              " 'spaCy': 0.8888888888888888,\n",
              " 'library': 0.4444444444444444,\n",
              " 'powerful': 0.1111111111111111,\n",
              " 'tool': 0.1111111111111111,\n",
              " 'offering': 0.1111111111111111,\n",
              " 'robust': 0.1111111111111111,\n",
              " 'support': 0.1111111111111111,\n",
              " 'processing': 0.1111111111111111,\n",
              " 'tasks': 0.2222222222222222,\n",
              " 'SpaCy': 0.1111111111111111,\n",
              " 'open': 0.1111111111111111,\n",
              " 'source': 0.1111111111111111,\n",
              " 'excels': 0.1111111111111111,\n",
              " 'providing': 0.1111111111111111,\n",
              " 'efficient': 0.1111111111111111,\n",
              " 'linguistic': 0.2222222222222222,\n",
              " 'annotations': 0.1111111111111111,\n",
              " 'large': 0.1111111111111111,\n",
              " 'volumes': 0.1111111111111111,\n",
              " 'Leveraging': 0.1111111111111111,\n",
              " 'trained': 0.1111111111111111,\n",
              " 'facilitates': 0.1111111111111111,\n",
              " 'syntactic': 0.1111111111111111,\n",
              " 'forming': 0.1111111111111111,\n",
              " 'solid': 0.1111111111111111,\n",
              " 'foundation': 0.1111111111111111,\n",
              " 'simplicity': 0.1111111111111111,\n",
              " 'speed': 0.1111111111111111,\n",
              " 'popular': 0.1111111111111111,\n",
              " 'choice': 0.1111111111111111,\n",
              " 'developers': 0.1111111111111111,\n",
              " 'researchers': 0.1111111111111111,\n",
              " 'working': 0.1111111111111111,\n",
              " 'specifically': 0.1111111111111111,\n",
              " 'employed': 0.1111111111111111,\n",
              " 'conjunction': 0.1111111111111111,\n",
              " 'Extractive': 0.1111111111111111,\n",
              " 'instance': 0.1111111111111111,\n",
              " 'benefits': 0.1111111111111111,\n",
              " 'sentence': 0.1111111111111111,\n",
              " 'allowing': 0.1111111111111111,\n",
              " 'identification': 0.1111111111111111,\n",
              " 'key': 0.1111111111111111,\n",
              " 'sentences': 0.2222222222222222,\n",
              " 'based': 0.1111111111111111,\n",
              " 'features': 0.1111111111111111,\n",
              " 'integration': 0.1111111111111111,\n",
              " 'machine': 0.1111111111111111,\n",
              " 'frameworks': 0.1111111111111111,\n",
              " 'enhances': 0.1111111111111111,\n",
              " 'adaptability': 0.1111111111111111,\n",
              " 'specific': 0.1111111111111111,\n",
              " 'requirements': 0.1111111111111111,\n",
              " 'renowned': 0.1111111111111111,\n",
              " 'efficiency': 0.1111111111111111,\n",
              " 'ease': 0.1111111111111111,\n",
              " 'use': 0.1111111111111111,\n",
              " 'essential': 0.1111111111111111,\n",
              " 'note': 0.1111111111111111,\n",
              " 'abstractive': 0.1111111111111111,\n",
              " 'involves': 0.1111111111111111,\n",
              " 'generating': 0.1111111111111111,\n",
              " 'new': 0.1111111111111111,\n",
              " 'requires': 0.1111111111111111,\n",
              " 'sophisticated': 0.1111111111111111,\n",
              " 'primary': 0.1111111111111111,\n",
              " 'remains': 0.1111111111111111,\n",
              " 'asset': 0.1111111111111111,\n",
              " 'preprocessing': 0.1111111111111111,\n",
              " 'stages': 0.1111111111111111,\n",
              " 'pipelines': 0.1111111111111111,\n",
              " 'contributing': 0.1111111111111111,\n",
              " 'overall': 0.1111111111111111,\n",
              " 'effectiveness': 0.1111111111111111,\n",
              " 'field': 0.1111111111111111,\n",
              " 'advance': 0.1111111111111111,\n",
              " 'likely': 0.1111111111111111,\n",
              " 'play': 0.1111111111111111,\n",
              " 'crucial': 0.1111111111111111,\n",
              " 'role': 0.1111111111111111,\n",
              " 'development': 0.1111111111111111,\n",
              " 'implementation': 0.1111111111111111,\n",
              " 'innovative': 0.1111111111111111}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the document into individual sentences\n",
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "sentence_tokens\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cHpX_iGL64u",
        "outputId": "daac5d00-eddc-43c9-adeb-0a5a977ba1e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"\"\"Natural Language Processing (NLP) stands at the forefront of artificial intelligence, revolutionizing the interaction between machines and human language.,\n",
              " Rooted in the convergence of computer science, linguistics, and cognitive psychology, NLP equips computers with the ability to comprehend, interpret, and respond to natural language in a contextually aware and semantically accurate manner.,\n",
              " Its core components, including tokenization, part-of-speech tagging, named entity recognition, parsing, and sentiment analysis, form the building blocks for various applications.,\n",
              " From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data.,\n",
              " Recent strides, exemplified by models like OpenAI GPT-3, showcase the prowess of deep learning and pre-training techniques, albeit accompanied by ethical considerations and challenges surrounding bias, data privacy, and environmental impact.,\n",
              " As NLP continues to evolve, it promises a future where machines understand and generate language with unprecedented sophistication, shaping the landscape of human-computer interaction. ,\n",
              " In the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization.,\n",
              " SpaCy is an open-source library that excels in providing efficient and accurate linguistic annotations for large volumes of text.,\n",
              " Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks.,\n",
              " The library simplicity and speed make it a popular choice for developers and researchers working on NLP applications.,\n",
              " For text summarization specifically, spaCy can be employed in conjunction with other techniques.,\n",
              " Extractive summarization, for instance, benefits from spaCy sentence parsing capabilities, allowing the identification of key sentences based on linguistic features.,\n",
              " Moreover, spaCy integration with machine learning frameworks enhances its adaptability to specific summarization requirements.,\n",
              " While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities.,\n",
              " However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications.,\n",
              " As the field continues to advance, spaCy is likely to play a crucial role in the development and implementation of innovative text summarization techniques.,\n",
              " \"\"\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of sentences in the document\n",
        "len(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkJ_1mp-L_f7",
        "outputId": "c78fd31f-5f81-4f54-ccf0-a04939568ac6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate a score for each sentence based on the normalized word frequencies\n",
        "sentence_scores = {}\n",
        "for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():\n",
        "            if sent not in sentence_scores.keys():\n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "\n",
        "# Display the sentence scores\n",
        "sentence_scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y38O7Q5NMD0F",
        "outputId": "ffbc8259-5684-436b-9815-c38595bdb194"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"\"\"Natural Language Processing (NLP) stands at the forefront of artificial intelligence, revolutionizing the interaction between machines and human language.: 2.4444444444444446,\n",
              " Rooted in the convergence of computer science, linguistics, and cognitive psychology, NLP equips computers with the ability to comprehend, interpret, and respond to natural language in a contextually aware and semantically accurate manner.: 2.6666666666666674,\n",
              " Its core components, including tokenization, part-of-speech tagging, named entity recognition, parsing, and sentiment analysis, form the building blocks for various applications.: 3.222222222222223,\n",
              " From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data.: 5.444444444444441,\n",
              " Recent strides, exemplified by models like OpenAI GPT-3, showcase the prowess of deep learning and pre-training techniques, albeit accompanied by ethical considerations and challenges surrounding bias, data privacy, and environmental impact.: 3.2222222222222228,\n",
              " As NLP continues to evolve, it promises a future where machines understand and generate language with unprecedented sophistication, shaping the landscape of human-computer interaction. : 2.666666666666667,\n",
              " In the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization.: 5.111111111111112,\n",
              " SpaCy is an open-source library that excels in providing efficient and accurate linguistic annotations for large volumes of text.: 2.555555555555556,\n",
              " Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks.: 4.333333333333334,\n",
              " The library simplicity and speed make it a popular choice for developers and researchers working on NLP applications.: 1.5555555555555558,\n",
              " For text summarization specifically, spaCy can be employed in conjunction with other techniques.: 2.4444444444444446,\n",
              " Extractive summarization, for instance, benefits from spaCy sentence parsing capabilities, allowing the identification of key sentences based on linguistic features.: 3.0000000000000004,\n",
              " Moreover, spaCy integration with machine learning frameworks enhances its adaptability to specific summarization requirements.: 2.0,\n",
              " While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities.: 3.333333333333334,\n",
              " However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications.: 3.666666666666667,\n",
              " As the field continues to advance, spaCy is likely to play a crucial role in the development and implementation of innovative text summarization techniques.: 3.333333333333334}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nlargest function from heapq module\n",
        "from heapq import nlargest\n",
        "\n",
        "# Determine the length of the summary (30% of the total number of sentences)\n",
        "select_length = int(len(sentence_tokens) * 0.3)\n",
        "\n",
        "# Display the selected length for the summary\n",
        "select_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz2-w15WMG65",
        "outputId": "cb25118e-d6eb-4f5f-de56-f666ac7609ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the final summary using the nlargest function\n",
        "summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "# Display the summary\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acGZuM9AMKcy",
        "outputId": "ba4d0cd5-04a7-4b9f-fb3f-7257f10aa8ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data.,\n",
              " In the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization.,\n",
              " Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks.,\n",
              " However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications.,\n",
              " While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities.]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the text from the selected summary sentences\n",
        "final_summary = [word.text for word in summary]\n",
        "\n",
        "# Display the final summary\n",
        "final_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22AzV67qMOI3",
        "outputId": "1f836fbc-19db-48a6-a655-38a3de3855a3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From the conversational capabilities of chatbots and virtual assistants to language translation, information extraction, text summarization, and speech recognition, NLP permeates diverse sectors, enhancing user experiences and extracting valuable insights from unstructured data.',\n",
              " 'In the realm of Natural Language Processing (NLP), the spaCy library stands as a powerful tool, offering robust support for various text processing tasks, including text summarization.',\n",
              " 'Leveraging pre-trained models, spaCy facilitates tokenization, part-of-speech tagging, named entity recognition, and syntactic parsing, forming a solid foundation for summarization tasks.',\n",
              " 'However, the library remains a valuable asset in the preprocessing stages of text summarization pipelines, contributing to the overall effectiveness of NLP applications.',\n",
              " 'While spaCy is renowned for its efficiency and ease of use, it essential to note that abstractive summarization, which involves generating new sentences, often requires more sophisticated models beyond spaCy primary capabilities.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"summary.txt\"\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(file_name, \"w\") as file:\n",
        "    # Write each element of the list to the file\n",
        "    for item in final_summary:\n",
        "        file.write(f\"{item}\\n\")\n",
        "\n",
        "print(f\"Summary For your Text is saved to this file. {file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjnOKvpQMSPY",
        "outputId": "633e7f64-c442-451b-f829-657e45772536"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary For your Text is saved to this file. summary.txt\n"
          ]
        }
      ]
    }
  ]
}